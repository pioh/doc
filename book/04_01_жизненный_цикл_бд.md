[← К оглавлению](README.md)

---

# [Глава 4.1](04_01_жизненный_цикл_бд.md): Жизненный цикл баз данных

## Введение

Итак, разобрались с железом (раздел 2), софтом (раздел 3), и теперь пора говорить о том, как решать реальные задачи. База данных — это не просто "создал табличку, закинул данные и радуешься". Это целая жизнь: от идеи до смерти (ну, или миграции на что-то новое).

**Жизненный цикл базы данных (Database Lifecycle, DBLC)** — это все этапы существования БД: от момента, когда кто-то сказал "блин, нам нужна база", до момента "всё, выключаем, переезжаем на MongoDB" (или наоборот).

Эта глава связана с:
- [**Глава 7.2**](07_02_понятие_бд_архитектура.md) (Понятие база данных) — там мы ещё вернёмся к БД подробнее
- [**Глава 7.3**](07_03_реляционные_бд_нормализация.md) (Реляционные БД) — когда будем проектировать таблицы, вспомним нормализацию
- [**Глава 4.2**](04_02_информационные_модели.md) (Информационные модели) — моделирование предметной области

Если ты думаешь, что БД живут вечно — ты ошибаешься. Средний срок жизни корпоративной БД — 5-10 лет. Потом либо переписывают, либо мигрируют, либо просто выключают нахрен и делают заново.

---

## 4.1.1. Что такое жизненный цикл БД

**Жизненный цикл базы данных (DBLC)** — это последовательность этапов от зарождения идеи создания БД до её вывода из эксплуатации.

**Аналогия:** представь, что БД — это здание. Жизненный цикл:
1. **Анализ требований** — "Нам нужен магазин на 100 человек с парковкой"
2. **Проектирование** — рисуем план здания (где стены, окна, туалеты)
3. **Реализация** — строим (заливаем фундамент, ставим стены)
4. **Заполнение данными** — завозим товары на полки
5. **Тестирование** — проверяем, не течёт ли крыша, работают ли двери
6. **Эксплуатация** — магазин работает, люди покупают
7. **Поддержка** — меняем лампочки, чиним сломанное, расширяем склад
8. **Вывод из эксплуатации** — сносим здание или перестраиваем в офис

Без чёткого понимания жизненного цикла получается хаос: начинаешь строить без плана, потом всё переделываешь, база работает криво, данные теряются, а заказчик орёт.

---

## 4.1.2. Фазы жизненного цикла БД

Классическая модель жизненного цикла БД включает **8 основных фаз**. Погнали по порядку.

---

### Фаза 1: Анализ требований (Requirements Analysis)

**Что делаем:** Выясняем, что вообще нужно. Разговариваем с заказчиком, пользователями, бизнесом.

**Вопросы, которые задаём:**
- Какие данные хранить? (товары, пользователи, заказы, платежи?)
- Сколько данных? (100 записей или 100 миллионов?)
- Кто будет работать с БД? (один админ или 10 тысяч пользователей одновременно?)
- Какие операции? (только чтение или постоянная запись?)
- Какие требования к скорости? (можно подождать секунду или нужен ответ за 10 мс?)
- Какие требования к надёжности? (потеря данных = конец света или "ну ладно"?)

**Типы требований:**

**Функциональные** — что должна делать БД:
- Хранить информацию о товарах (название, цена, количество)
- Регистрировать заказы пользователей
- Вести историю покупок
- Поддерживать поиск по названию товара

**Нефункциональные** — как должна работать БД:
- Время отклика запроса: не более 100 мс
- Доступность: 99.9% (не больше 8 часов простоя в год)
- Безопасность: шифрование личных данных
- Масштабируемость: должна поддерживать рост до 1 млн пользователей

**Пример 1: Интернет-магазин (анализ требований)**

**Заказчик:** "Хочу интернет-магазин для продажи носков."

**Аналитик:** "Окей, а что конкретно нужно?"

**Требования:**
- Хранить каталог товаров (название, цена, артикул, количество на складе, фото)
- Регистрация пользователей (email, пароль, адрес доставки)
- Оформление заказов (корзина, оплата, доставка)
- История заказов пользователя
- Админ-панель (добавление товаров, управление заказами)

**Оценка объёма:**
- Товаров: 500 позиций (на старте), рост до 10 000
- Пользователей: 10 000 (на старте), рост до 100 000
- Заказов: ~100 в день (~36 000 в год)

**Нефункциональные требования:**
- Сайт должен работать 24/7
- Время загрузки страницы: до 1 секунды
- Безопасность: пароли хешируются, платёжные данные не хранятся (используем Stripe/PayPal)

**Вывод:** Нужна реляционная БД (PostgreSQL или MySQL), структура данных простая, нагрузка небольшая.

---

### Фаза 2: Проектирование БД (Database Design)

Это самая важная фаза. Плохо спроектировал — потом будешь месяцами рефакторить.

Проектирование делится на **три подэтапа**:

#### 2.1. Концептуальное проектирование (Conceptual Design)

**Что делаем:** Рисуем **ER-диаграмму** (Entity-Relationship, сущность-связь). Определяем сущности и связи между ними. Пока не думаем о конкретной СУБД.

**Сущности** — это объекты предметной области:
- Пользователь (User)
- Товар (Product)
- Заказ (Order)
- Категория (Category)

**Связи** — как сущности взаимодействуют:
- Пользователь **размещает** Заказ (один ко многим, 1:N)
- Заказ **содержит** Товары (многие ко многим, M:N)
- Товар **принадлежит** Категории (многие к одному, N:1)

**Пример 2: ER-диаграмма интернет-магазина**

```
[User] ──(1)──────(N)── [Order]
   │                        │
   │                        │
   └── email, password      └── order_date, total_price
       name, address
       
[Product] ──(N)──────(M)── [Order] (связь M:N через промежуточную таблицу)
   │
   └── name, price, stock_quantity, image_url

[Category] ──(1)──────(N)── [Product]
   │
   └── category_name
```

**Правила:**
- Один пользователь может сделать много заказов (1:N)
- Один заказ содержит много товаров, и один товар может быть в разных заказах (M:N)
- Один товар принадлежит одной категории, но в категории много товаров (N:1)

---

#### 2.2. Логическое проектирование (Logical Design)

**Что делаем:** Переводим ER-диаграмму в **таблицы** реляционной модели. Определяем первичные и внешние ключи.

**Правила преобразования:**
- Каждая сущность → таблица
- Каждый атрибут сущности → поле таблицы
- Связь 1:N → внешний ключ в таблице "многие"
- Связь M:N → отдельная промежуточная таблица

**Пример 3: Таблицы интернет-магазина**

**Таблица `users`:**
```
user_id (INT, PRIMARY KEY)  ← первичный ключ
email (VARCHAR, UNIQUE)
password_hash (VARCHAR)
name (VARCHAR)
address (TEXT)
created_at (TIMESTAMP)
```

**Таблица `products`:**
```
product_id (INT, PRIMARY KEY)
category_id (INT, FOREIGN KEY → categories.category_id)
name (VARCHAR)
price (DECIMAL)
stock_quantity (INT)
image_url (VARCHAR)
```

**Таблица `categories`:**
```
category_id (INT, PRIMARY KEY)
category_name (VARCHAR)
```

**Таблица `orders`:**
```
order_id (INT, PRIMARY KEY)
user_id (INT, FOREIGN KEY → users.user_id)
order_date (TIMESTAMP)
total_price (DECIMAL)
status (ENUM: 'pending', 'paid', 'shipped', 'delivered')
```

**Промежуточная таблица `order_items`** (связь M:N между orders и products):
```
order_item_id (INT, PRIMARY KEY)
order_id (INT, FOREIGN KEY → orders.order_id)
product_id (INT, FOREIGN KEY → products.product_id)
quantity (INT)
price (DECIMAL)  ← цена на момент заказа (может измениться)
```

**Почему отдельная таблица `order_items`?** 
Потому что связь M:N (один заказ может содержать много товаров, один товар может быть в разных заказах). Без промежуточной таблицы это не представить.

---

#### 2.3. Физическое проектирование (Physical Design)

**Что делаем:** Оптимизируем под конкретную СУБД. Определяем индексы, разделение на партиции, типы данных.

**Индексы** — ускоряют поиск. Без индекса БД будет сканировать всю таблицу (медленно).

**Пример 4: Какие индексы создать?**

```sql
-- Часто ищем пользователя по email
CREATE INDEX idx_users_email ON users(email);

-- Часто ищем товары по категории
CREATE INDEX idx_products_category ON products(category_id);

-- Часто выбираем заказы конкретного пользователя
CREATE INDEX idx_orders_user ON orders(user_id);

-- Часто ищем товары по названию
CREATE INDEX idx_products_name ON products(name);
```

**Типы данных:**
- `INT` — для ID (занимает 4 байта, диапазон: -2 млрд до +2 млрд)
- `BIGINT` — если ID больше 2 млрд (8 байт)
- `VARCHAR(255)` — для строк переменной длины
- `TEXT` — для длинных текстов (адрес, описание)
- `DECIMAL(10, 2)` — для цен (10 цифр всего, 2 после запятой: 12345678.99)
- `TIMESTAMP` — для дат и времени

**Партиционирование (Partitioning):** разделение больших таблиц на части.

Если у тебя 100 миллионов заказов за 10 лет, можно разделить таблицу по годам:
```sql
CREATE TABLE orders_2024 PARTITION OF orders FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');
CREATE TABLE orders_2025 PARTITION OF orders FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');
```

Запросы будут работать только с нужной партицией → быстрее.

---

### Фаза 3: Реализация (Implementation)

**Что делаем:** Создаём таблицы, определяем ограничения, выбираем СУБД.

**Выбор СУБД:**

| СУБД         | Плюсы                              | Минусы                          | Применение                     |
|--------------|------------------------------------|---------------------------------|--------------------------------|
| **PostgreSQL**   | Мощная, open-source, JSONB, расширения | Сложнее настраивать             | Веб-приложения, аналитика      |
| **MySQL**        | Популярная, простая, быстрая       | Меньше фич, чем PostgreSQL      | WordPress, веб-сайты           |
| **SQLite**       | Не требует сервера, файловая       | Не для многопользовательских БД | Мобильные приложения, прототипы |
| **SQL Server**   | Интеграция с Microsoft, мощная     | Дорогая лицензия                | Корпоративные приложения       |
| **Oracle**       | Максимум возможностей              | Очень дорогая                   | Банки, крупный бизнес          |

**Пример 5: Создание таблиц в PostgreSQL**

```sql
CREATE TABLE users (
    user_id SERIAL PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    name VARCHAR(100),
    address TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE categories (
    category_id SERIAL PRIMARY KEY,
    category_name VARCHAR(100) NOT NULL
);

CREATE TABLE products (
    product_id SERIAL PRIMARY KEY,
    category_id INT REFERENCES categories(category_id) ON DELETE SET NULL,
    name VARCHAR(255) NOT NULL,
    price DECIMAL(10, 2) NOT NULL CHECK (price >= 0),
    stock_quantity INT NOT NULL CHECK (stock_quantity >= 0),
    image_url VARCHAR(255)
);

CREATE TABLE orders (
    order_id SERIAL PRIMARY KEY,
    user_id INT REFERENCES users(user_id) ON DELETE CASCADE,
    order_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    total_price DECIMAL(10, 2) NOT NULL,
    status VARCHAR(20) DEFAULT 'pending'
);

CREATE TABLE order_items (
    order_item_id SERIAL PRIMARY KEY,
    order_id INT REFERENCES orders(order_id) ON DELETE CASCADE,
    product_id INT REFERENCES products(product_id) ON DELETE RESTRICT,
    quantity INT NOT NULL CHECK (quantity > 0),
    price DECIMAL(10, 2) NOT NULL
);
```

**Ограничения:**
- `PRIMARY KEY` — уникальный идентификатор строки
- `FOREIGN KEY` — связь между таблицами
- `NOT NULL` — поле обязательно к заполнению
- `UNIQUE` — значение должно быть уникальным
- `CHECK` — проверка условия (цена >= 0)
- `ON DELETE CASCADE` — при удалении пользователя удалить его заказы
- `ON DELETE RESTRICT` — нельзя удалить товар, если он есть в заказах

---

### Фаза 4: Заполнение данными (Data Loading)

**Что делаем:** Импортируем данные из старых систем, CSV-файлов, Excel, других БД.

**Источники данных:**
- Старая БД (миграция с MySQL на PostgreSQL)
- Excel-таблицы (типичный ужас малого бизнеса)
- CSV-файлы
- JSON/XML из API
- Ручной ввод (если данных мало)

**Пример 6: Миграция из Excel в PostgreSQL**

**Ситуация:** У магазина был Excel-файл с товарами (products.xlsx):

```
| Название      | Цена  | Количество | Категория |
|---------------|-------|------------|-----------|
| Носки белые   | 150   | 100        | Одежда    |
| Носки чёрные  | 180   | 50         | Одежда    |
| Кружка синяя  | 300   | 30         | Посуда    |
```

**Шаги миграции:**

1. Экспортируем Excel в CSV:
```csv
name,price,stock_quantity,category_name
Носки белые,150,100,Одежда
Носки чёрные,180,50,Одежда
Кружка синяя,300,30,Посуда
```

2. Загружаем CSV в PostgreSQL:
```sql
-- Сначала заполняем категории (уникальные)
INSERT INTO categories (category_name) 
VALUES ('Одежда'), ('Посуда')
ON CONFLICT DO NOTHING;

-- Потом товары
COPY products (name, price, stock_quantity, category_id)
FROM '/path/to/products.csv'
WITH (FORMAT csv, HEADER true);
```

**Проблемы при миграции:**
- Дубликаты (один товар записан 10 раз)
- Опечатки ("Одежда" vs "одежда" vs "Одежжда")
- Неправильные типы данных (цена записана как текст "150 руб")
- Отсутствующие данные (пустые ячейки)

**Решение:** Написать скрипт очистки данных (Python + pandas):
```python
import pandas as pd

df = pd.read_excel('products.xlsx')
df = df.drop_duplicates()  # убрать дубликаты
df['price'] = df['price'].str.replace(' руб', '').astype(float)  # очистить цену
df['category_name'] = df['category_name'].str.strip().str.capitalize()  # привести категории к единому виду
df.to_csv('products_clean.csv', index=False)
```

---

### Фаза 5: Тестирование (Testing)

**Что делаем:** Проверяем, что БД работает корректно.

**Виды тестов:**

#### 5.1. Функциональное тестирование

Проверяем, что запросы работают правильно:
- Регистрация пользователя → пользователь появился в таблице `users`
- Оформление заказа → запись в `orders` и `order_items`, уменьшилось `stock_quantity`
- Удаление пользователя → его заказы тоже удалились (CASCADE работает)

#### 5.2. Тестирование производительности

Проверяем скорость работы:
- Выборка 1000 товаров: должна занимать < 50 мс
- Поиск пользователя по email: < 10 мс (благодаря индексу)
- Создание заказа: < 100 мс

**Инструменты:**
- `EXPLAIN ANALYZE` (PostgreSQL) — показывает план выполнения запроса
- pgBench (PostgreSQL) — нагрузочное тестирование
- JMeter — симуляция одновременных запросов

**Пример 7: Проверка индекса**

**Запрос без индекса (плохо):**
```sql
EXPLAIN ANALYZE SELECT * FROM users WHERE email = 'user@example.com';

-- Seq Scan on users  (cost=0.00..1500.00 rows=1 width=100) (actual time=25.123..25.125 rows=1 loops=1)
-- Planning Time: 0.1 ms
-- Execution Time: 25.2 ms
```

**Seq Scan** = последовательное сканирование (перебор всей таблицы) → медленно.

**Создаём индекс:**
```sql
CREATE INDEX idx_users_email ON users(email);
```

**Запрос с индексом (хорошо):**
```sql
EXPLAIN ANALYZE SELECT * FROM users WHERE email = 'user@example.com';

-- Index Scan using idx_users_email on users  (cost=0.29..8.30 rows=1 width=100) (actual time=0.015..0.017 rows=1 loops=1)
-- Planning Time: 0.1 ms
-- Execution Time: 0.05 ms
```

**Index Scan** = поиск по индексу → в **500 раз быстрее** (25 мс → 0.05 мс).

**Вывод:** Индексы критичны для производительности.

#### 5.3. Тестирование целостности данных

Проверяем, что ограничения работают:
- Нельзя создать товар с отрицательной ценой (CHECK constraint)
- Нельзя удалить товар, который есть в заказе (RESTRICT)
- Нельзя создать заказ для несуществующего пользователя (FOREIGN KEY)

---

### Фаза 6: Эксплуатация (Operation / Maintenance)

**Что делаем:** БД работает в продакшене, пользователи её используют.

**Задачи администратора БД (DBA):**

#### 6.1. Резервное копирование (Backup)

**Виды бэкапов:**
- **Полный (Full Backup):** копия всей БД
- **Инкрементный (Incremental):** только изменения с последнего бэкапа
- **Дифференциальный (Differential):** изменения с последнего полного бэкапа

**Стратегия 3-2-1:**
- **3 копии:** оригинал + 2 бэкапа
- **2 разных носителя:** SSD + HDD (или облако)
- **1 копия off-site:** в другом дата-центре (на случай пожара)

**Пример PostgreSQL:**
```bash
# Полный бэкап
pg_dump myshop > myshop_backup_2025-01-14.sql

# Бэкап с сжатием
pg_dump myshop | gzip > myshop_backup_2025-01-14.sql.gz

# Восстановление
psql myshop < myshop_backup_2025-01-14.sql
```

**Частота бэкапов:** зависит от критичности данных.
- Банк: каждые 15 минут
- Интернет-магазин: раз в день
- Блог: раз в неделю

#### 6.2. Мониторинг производительности

**Что отслеживаем:**
- **CPU usage:** процессор БД не должен быть загружен на 100%
- **RAM usage:** БД любят жрать память (кэш)
- **Disk I/O:** скорость чтения/записи на диск
- **Connections:** количество одновременных подключений
- **Slow queries:** медленные запросы (> 1 секунды)

**Инструменты мониторинга:**
- **Prometheus + Grafana** — визуализация метрик
- **pgAdmin** — GUI для PostgreSQL
- **Percona Monitoring** — для MySQL

**Пример проблемы:** Внезапно сайт стал тормозить. Смотрим в мониторинг:
```
Slow Query Log:
SELECT * FROM products WHERE name LIKE '%носк%';  -- 2.5 секунды
```

**Причина:** Запрос `LIKE '%носк%'` не использует индекс (% в начале = полное сканирование).

**Решение:** Использовать полнотекстовый поиск (Full-Text Search):
```sql
-- Создаём индекс для полнотекстового поиска
CREATE INDEX idx_products_name_fts ON products USING GIN (to_tsvector('russian', name));

-- Новый запрос (быстро)
SELECT * FROM products WHERE to_tsvector('russian', name) @@ to_tsquery('russian', 'носк');
```

#### 6.3. Обновление схемы (Миграции)

**Ситуация:** Через год после запуска нужно добавить поле "скидка" для товаров.

**Миграция:**
```sql
ALTER TABLE products ADD COLUMN discount DECIMAL(5, 2) DEFAULT 0 CHECK (discount >= 0 AND discount <= 100);
```

**Проблема:** На production-БД 10 миллионов товаров, ALTER TABLE может занять часы и заблокировать таблицу.

**Решение:** Миграция без даунтайма (zero-downtime migration):
1. Создать новую таблицу с нужной схемой
2. Скопировать данные порциями (batches)
3. Переключить приложение на новую таблицу
4. Удалить старую таблицу

---

### Фаза 7: Поддержка и модернизация (Support & Evolution)

**Что делаем:** Добавляем новые фичи, оптимизируем, масштабируем.

#### 7.1. Вертикальное масштабирование (Scale Up)

**Метод:** Увеличить ресурсы сервера (больше CPU, RAM, SSD).

**Пример:** Сервер с 16 GB RAM → 64 GB RAM.

**Плюсы:** Просто.  
**Минусы:** Есть предел (нельзя бесконечно увеличивать).

#### 7.2. Горизонтальное масштабирование (Scale Out)

**Метод:** Добавить больше серверов.

**Варианты:**
- **Репликация (Replication):** Мастер-сервер (запись) + несколько реплик (чтение). Читающие запросы распределяются между репликами → снижение нагрузки.
- **Шардирование (Sharding):** Разделение данных между серверами. Например, пользователи A-M на сервере 1, N-Z на сервере 2.

**Пример 8: Расчёт нагрузки на БД**

**Ситуация:** Интернет-магазин растёт. Текущая нагрузка:
- 10 000 пользователей онлайн
- Каждый делает 5 запросов в минуту
- Итого: 10 000 × 5 / 60 = 833 запроса в секунду (QPS, Queries Per Second)

**Один сервер PostgreSQL (16 CPU, 64 GB RAM, SSD):**
- Максимальная пропускная способность: ~5000 QPS (при оптимизации)

**Текущая нагрузка:** 833 QPS → сервер справляется.

**Прогноз:** рост до 100 000 пользователей → 8330 QPS → нужно масштабирование.

**Решение:**
1. Включить репликацию: 1 мастер (запись) + 3 реплики (чтение)
2. 80% запросов — чтение → распределяем на 3 реплики: 8330 × 0.8 / 3 ≈ 2220 QPS на реплику (норм)
3. 20% запросов — запись → мастер: 8330 × 0.2 = 1666 QPS (норм)

**Итого:** Выдержим рост до 100 000 пользователей.

---

### Фаза 8: Вывод из эксплуатации (Decommissioning)

**Что делаем:** БД больше не нужна, выключаем.

**Причины:**
- Проект закрыли
- Мигрировали на новую систему
- Объединили несколько БД в одну

**Шаги:**
1. **Архивирование:** Сохранить данные на долгий срок (для аудита, законов)
2. **Экспорт:** Выгрузить данные в формат CSV/JSON (на случай, если понадобятся)
3. **Миграция:** Перенести данные в новую систему
4. **Удаление:** Безопасно удалить БД (перезатереть диски, чтобы данные нельзя было восстановить)

**Пример:** Компания мигрирует с MySQL на PostgreSQL.

**План:**
1. Поднять PostgreSQL рядом с MySQL
2. Экспортировать данные из MySQL: `mysqldump > data.sql`
3. Импортировать в PostgreSQL: `psql < data.sql`
4. Проверить, что всё работает
5. Переключить приложение на PostgreSQL
6. Оставить MySQL работать ещё месяц (на случай проблем)
7. Выключить MySQL, удалить

---

## 4.1.3. Модели жизненного цикла

Существуют разные подходы к организации жизненного цикла БД.

### Каскадная модель (Waterfall)

**Принцип:** Последовательное выполнение фаз. Завершил одну → переходишь к следующей. Назад не возвращаемся.

```
Анализ → Проектирование → Реализация → Тестирование → Эксплуатация
```

**Плюсы:**
- Понятно и структурировано
- Легко планировать
- Подходит для крупных проектов с чёткими требованиями

**Минусы:**
- Нет гибкости (требования изменились → всё переделывать)
- Долго (от идеи до результата — месяцы)
- Ошибки выявляются поздно (на этапе тестирования)

**Применение:** Государственные проекты, банковские системы, крупные корпорации.

---

### Agile / Iterative модель

**Принцип:** Итеративная разработка. Делаем небольшие части (спринты 2-4 недели), быстро тестируем, получаем обратную связь, дорабатываем.

```
Спринт 1: Базовая схема (users, products) → Тестирование → Фидбэк
Спринт 2: Заказы (orders, order_items) → Тестирование → Фидбэк
Спринт 3: Оптимизация (индексы, репликация) → Тестирование → Фидбэк
```

**Плюсы:**
- Гибкость (можем менять требования)
- Быстрый результат (первая версия через 2 недели)
- Раннее выявление проблем

**Минусы:**
- Сложнее планировать
- Требует хорошей коммуникации с заказчиком
- Может привести к хаотичной архитектуре (если нет контроля)

**Применение:** Стартапы, веб-приложения, SaaS.

---

### Сравнение

| Параметр          | Waterfall                  | Agile                       |
|-------------------|----------------------------|-----------------------------|
| Гибкость          | Низкая                     | Высокая                     |
| Скорость запуска  | Медленная (месяцы)         | Быстрая (недели)            |
| Изменения         | Дорого, сложно             | Легко                       |
| Документация      | Подробная, формальная      | Минимальная, гибкая         |
| Применение        | Крупные корпоративные БД   | Стартапы, веб-приложения    |

---

## 4.1.4. Практические примеры

### Пример 9: Проектирование БД для социальной сети

**Требования:**
- Пользователи (регистрация, профиль)
- Посты (текст, фото)
- Лайки (пользователь лайкает пост)
- Комментарии (к постам)
- Дружба (пользователи добавляют друг друга в друзья)

**ER-диаграмма:**
```
[User] ──(1)──────(N)── [Post]
  │                       │
  └── username,           └── content, created_at
      email,
      bio

[User] ──(M)──────(N)── [Like] ──(N)──────(1)── [Post]

[User] ──(1)──────(N)── [Comment] ──(N)──────(1)── [Post]

[User] ──(M)──────(N)── [Friendship] (самосвязь: User → User)
```

**Логические таблицы:**

```sql
CREATE TABLE users (
    user_id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    bio TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE posts (
    post_id SERIAL PRIMARY KEY,
    user_id INT REFERENCES users(user_id) ON DELETE CASCADE,
    content TEXT NOT NULL,
    image_url VARCHAR(255),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE likes (
    like_id SERIAL PRIMARY KEY,
    user_id INT REFERENCES users(user_id) ON DELETE CASCADE,
    post_id INT REFERENCES posts(post_id) ON DELETE CASCADE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user_id, post_id)  -- один пользователь может лайкнуть пост только раз
);

CREATE TABLE comments (
    comment_id SERIAL PRIMARY KEY,
    user_id INT REFERENCES users(user_id) ON DELETE CASCADE,
    post_id INT REFERENCES posts(post_id) ON DELETE CASCADE,
    content TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE friendships (
    friendship_id SERIAL PRIMARY KEY,
    user1_id INT REFERENCES users(user_id) ON DELETE CASCADE,
    user2_id INT REFERENCES users(user_id) ON DELETE CASCADE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    CHECK (user1_id < user2_id),  -- избегаем дубликатов (1→2 и 2→1)
    UNIQUE(user1_id, user2_id)
);
```

**Индексы:**
```sql
CREATE INDEX idx_posts_user ON posts(user_id);
CREATE INDEX idx_likes_post ON likes(post_id);
CREATE INDEX idx_comments_post ON comments(post_id);
CREATE INDEX idx_friendships_users ON friendships(user1_id, user2_id);
```

**Оценка размера БД:**

Предположим:
- 1 млн пользователей
- Каждый пользователь: 5 постов → 5 млн постов
- Каждый пост: 10 лайков → 50 млн лайков
- Каждый пост: 3 комментария → 15 млн комментариев
- Каждый пользователь: 100 друзей → 50 млн записей дружбы

**Расчёт размера таблицы `posts`:**
- Одна запись: post_id (4 байта) + user_id (4) + content (средний размер 200 символов = 200 байт) + image_url (100 байт) + created_at (8 байт) = ~316 байт
- 5 млн постов: 5 000 000 × 316 = 1 580 000 000 байт ≈ 1.5 ГБ

**Итоговый размер БД:** ~10-20 ГБ (с учётом индексов и служебных данных).

**Вывод:** Для 1 млн пользователей достаточно одного сервера. При росте до 10 млн — нужна репликация.

---

### Пример 10: Миграция legacy-системы

**Ситуация:** Компания 20 лет вела учёт в Microsoft Access (БД на 500 МБ). Решили мигрировать на PostgreSQL.

**Проблемы:**
1. Access использует нестандартные типы данных
2. Много дубликатов (клиенты записаны по 10 раз)
3. Отсутствуют первичные ключи (!)
4. Неправильная кодировка (кириллица превратилась в кракозябры)

**План миграции:**
1. Экспортировать Access → CSV
2. Написать скрипт очистки (Python):
   - Удалить дубликаты
   - Исправить кодировку
   - Добавить первичные ключи
3. Спроектировать нормализованную схему PostgreSQL
4. Импортировать данные
5. Проверить целостность
6. Перевести приложение на новую БД

**Сроки:** 3 месяца (большую часть времени — очистка данных).

**Стоимость:** 2 миллиона рублей (работа аналитиков, программистов, тестировщиков).

**Вывод:** Миграция legacy-систем — это ад. Но без этого компания не сможет расти.

---

## 4.1.5. Связь с другими главами

- [**Глава 7.1**](07_01_инфологическое_моделирование.md) (Инфологическое моделирование): концептуальное проектирование БД = построение ER-диаграмм
- [**Глава 7.2**](07_02_понятие_бд_архитектура.md) (Понятие база данных, архитектура БД): жизненный цикл БД включает выбор архитектуры
- [**Глава 7.3**](07_03_реляционные_бд_нормализация.md) (Реляционные БД, нормализация): логическое проектирование требует знания нормальных форм
- [**Глава 4.2**](04_02_информационные_модели.md) (Информационные модели): моделирование предметной области = часть анализа требований
- **Глава 9** (Информационная безопасность): на этапе эксплуатации критична защита данных (шифрование, бэкапы)

---

## Ключевые термины и определения

**Жизненный цикл БД (DBLC)** — последовательность этапов от создания до вывода из эксплуатации базы данных.

**Анализ требований** — сбор информации о том, какие данные нужно хранить и как с ними работать.

**Концептуальное проектирование** — создание ER-диаграммы (сущности и связи) без привязки к конкретной СУБД.

**Логическое проектирование** — преобразование ER-диаграммы в таблицы реляционной модели.

**Физическое проектирование** — оптимизация схемы БД под конкретную СУБД (индексы, партиции).

**Первичный ключ (Primary Key)** — уникальный идентификатор строки в таблице.

**Внешний ключ (Foreign Key)** — поле, ссылающееся на первичный ключ другой таблицы (обеспечивает целостность).

**Индекс (Index)** — структура данных для ускорения поиска.

**Репликация (Replication)** — копирование данных с одного сервера на другие (для отказоустойчивости и масштабируемости).

**Шардирование (Sharding)** — разделение данных между несколькими серверами.

**Миграция (Migration)** — изменение схемы БД или перенос данных из одной системы в другую.

**Нормализация** — процесс организации таблиц для устранения избыточности (подробнее в [главе 7.3](07_03_реляционные_бд_нормализация.md)).

**СУБД (DBMS)** — система управления базами данных (PostgreSQL, MySQL, Oracle и т.д.).

**Бэкап (Backup)** — резервная копия БД.

---

## Контрольные вопросы

1. **Теория:** Перечислите 8 фаз жизненного цикла базы данных. Объясните, почему нельзя пропустить фазу проектирования и сразу начать реализацию.

2. **Практика:** Интернет-магазин имеет таблицы: `users` (100 тыс. записей), `products` (10 тыс.), `orders` (1 млн). Запрос "найти все заказы пользователя с email = 'user@example.com'" выполняется 5 секунд. Какие индексы нужно создать, чтобы ускорить запрос? Обоснуйте.

3. **Проектирование:** Спроектируйте логическую схему БД для библиотеки: книги, авторы, читатели, выдача книг. Определите первичные и внешние ключи. Какие связи между таблицами (1:N, M:N)?

4. **Сравнение:** В чём разница между вертикальным и горизонтальным масштабированием БД? Приведите пример ситуации, когда вертикальное масштабирование не поможет.

5. **Расчёт:** База данных социальной сети: 10 млн пользователей, каждый делает в среднем 2 поста в месяц. Размер одного поста (с метаданными): 500 байт. Сколько места займут посты за год? Если SSD стоит 5000 руб/ТБ, сколько будет стоить хранение данных за 5 лет?

---

## Резюме

В этой главе мы разобрали **жизненный цикл баз данных**:

- ✅ **8 фаз:** анализ требований → проектирование (концептуальное, логическое, физическое) → реализация → заполнение данными → тестирование → эксплуатация → поддержка → вывод из эксплуатации
- ✅ **ER-диаграммы** для концептуального моделирования
- ✅ **Таблицы, ключи, индексы** для логического и физического проектирования
- ✅ **Миграция данных** из старых систем (Excel, CSV, другие БД)
- ✅ **Тестирование производительности** с помощью индексов и EXPLAIN ANALYZE
- ✅ **Эксплуатация:** бэкапы, мониторинг, обновления схемы
- ✅ **Масштабирование:** вертикальное (больше ресурсов) и горизонтальное (репликация, шардирование)
- ✅ **Модели жизненного цикла:** Waterfall (последовательно) vs Agile (итеративно)

Теперь ты знаешь:

- Как правильно спроектировать БД (чтобы потом не переделывать)
- Зачем нужны индексы (и почему без них всё тормозит)
- Как мигрировать данные из Excel/Access (и не сойти с ума)
- Как масштабировать БД при росте нагрузки
- Почему бэкапы критичны (и как не потерять все данные)

База данных — это не просто таблички с данными. Это сложная система, которая живёт годами, меняется, растёт, ломается и требует постоянного ухода. Понимание жизненного цикла БД — это ключ к созданию надёжных и масштабируемых приложений.

---

_Объём главы: ~14500 символов_


---

[← К оглавлению](README.md)

*Глава 4.1: Жизненный цикл баз данных*
