# Глава 1.5: Меры информации. Синтаксическая, семантическая, прагматическая меры

## Введение

Информация — фундаментальное понятие современной науки и технологии. Но как измерить информацию? Сколько информации содержится в книге, фотографии или сообщении? Оказывается, на этот вопрос нет однозначного ответа, так как информацию можно измерять с разных точек зрения.

Существуют три основных подхода к измерению информации: **синтаксический** (количественный), **семантический** (смысловой) и **прагматический** (ценностный). Каждый из этих подходов отражает различные аспекты информации и применяется в разных контекстах. Синтаксический подход отвечает на вопрос "сколько", семантический — "о чём", а прагматический — "насколько полезно".

Понимание различных мер информации критически важно для специалистов в области информационных технологий. Например, при проектировании систем хранения данных важна синтаксическая мера (сколько байтов занимает файл), при создании поисковых систем — семантическая (насколько релевантен документ запросу), а при разработке систем поддержки принятий — прагматическая (насколько полезна информация для достижения цели).

Эта глава тесно связана с главой 1.10 (свойства информации) и главой 1.12 (сжатие информации), так как понимание того, как измеряется информация, помогает оценить эффективность алгоритмов сжатия и понять природу информационных процессов.

## Синтаксическая мера информации

### Определение и сущность

**Синтаксическая мера информации** (также называемая **объёмной** или **количественной**) — это подход к измерению информации, при котором учитывается только количество символов, битов или сигналов, независимо от их смысла и ценности.

С синтаксической точки зрения информация рассматривается как последовательность символов из некоторого алфавита. Мера зависит только от количества этих символов и мощности алфавита, но не от содержания сообщения.

Синтаксическая мера имеет два основных подхода:
1. **Объёмный подход** — простой подсчёт объёма данных (биты, байты)
2. **Вероятностный подход** — учёт вероятности появления символов (энтропийный подход)

### Единицы измерения информации

Основная единица измерения информации — **бит** (binary digit, двоичная цифра).

**Бит** — это количество информации, необходимое для выбора одного из двух равновероятных вариантов (да/нет, 0/1, истина/ложь).

**Производные единицы:**

| Единица    | Обозначение | Соотношение                  | Количество байтов      |
|------------|-------------|------------------------------|------------------------|
| Бит        | бит         | 1 бит                        | —                      |
| Байт       | Б (B)       | 8 бит                        | 1                      |
| Килобайт   | КБ (KB)     | 1024 байта = 2¹⁰ байт        | 1 024                  |
| Мегабайт   | МБ (MB)     | 1024 КБ = 2²⁰ байт           | 1 048 576              |
| Гигабайт   | ГБ (GB)     | 1024 МБ = 2³⁰ байт           | 1 073 741 824          |
| Терабайт   | ТБ (TB)     | 1024 ГБ = 2⁴⁰ байт           | 1 099 511 627 776      |
| Петабайт   | ПБ (PB)     | 1024 ТБ = 2⁵⁰ байт           | 1 125 899 906 842 624  |

**Примечание:** Существует также система СИ, где приставки обозначают степени 1000, а не 1024:
- 1 кБ (килобайт) = 1000 байт
- 1 КиБ (кибибайт, KiB) = 1024 байта

В информатике чаще используется бинарная система (степени двойки).

### Формула Хартли (для равновероятных событий)

Американский инженер Ральф Хартли в 1928 году предложил формулу для расчёта количества информации при равновероятных событиях.

**Формула Хартли:**

```
I = log₂(N)
```

где:
- **I** — количество информации (в битах)
- **N** — количество возможных равновероятных событий (вариантов)
- **log₂** — логарифм по основанию 2

**Смысл формулы:** если имеется N равновероятных вариантов, то для указания одного из них требуется log₂(N) бит информации.

**Другая форма записи:**

```
N = 2^I
```

Эта форма удобна, когда известно количество бит и нужно найти количество вариантов.

**Важное следствие:** для удвоения количества вариантов достаточно добавить всего 1 бит информации.

### Формула Шеннона (для неравновероятных событий)

Клод Шеннон в 1948 году создал математическую теорию информации и предложил формулу для расчёта среднего количества информации (энтропии) при неравновероятных событиях.

**Формула Шеннона (энтропия):**

```
H = -∑(pᵢ × log₂(pᵢ))
```

где:
- **H** — энтропия (среднее количество информации на символ, в битах)
- **pᵢ** — вероятность появления i-го символа
- **∑** — сумма по всем возможным символам

**Смысл энтропии:** энтропия показывает среднее количество информации, приходящееся на один символ сообщения. Чем более неопределённым является источник, тем выше энтропия.

**Свойства энтропии:**
1. H ≥ 0 (энтропия неотрицательна)
2. H максимальна при равновероятных событиях (все pᵢ одинаковы)
3. H = 0 когда одно событие имеет вероятность 1 (полная определённость, нет информации)

**Связь с формулой Хартли:** если все события равновероятны (pᵢ = 1/N), то формула Шеннона превращается в формулу Хартли:

```
H = -∑(1/N × log₂(1/N)) = -N × (1/N) × log₂(1/N) = log₂(N)
```

### Примеры расчётов по формуле Хартли

**Пример 1:** Количество информации в бросании монеты

Монета может упасть орлом или решкой — 2 равновероятных исхода.

```
I = log₂(2) = 1 бит
```

Результат одного броска монеты несёт ровно 1 бит информации.

**Пример 2:** Количество информации в бросании игрального кубика

Кубик имеет 6 граней, каждая выпадает с вероятностью 1/6.

```
I = log₂(6) ≈ 2.585 бита
```

Результат броска кубика несёт примерно 2.585 бита информации.

**Пример 3:** Угадывание числа от 1 до 100

Имеется 100 возможных чисел, все равновероятны.

```
I = log₂(100) ≈ 6.644 бита
```

Для однозначного указания числа от 1 до 100 требуется примерно 6.644 бита, что соответствует 7 битам в двоичном представлении (2⁷ = 128 > 100).

**Пример 4:** Выбор символа из алфавита

Русский алфавит содержит 33 буквы. Если предположить, что все буквы равновероятны:

```
I = log₂(33) ≈ 5.044 бита
```

Каждая буква несёт примерно 5.044 бита информации.

Английский алфавит (26 букв):
```
I = log₂(26) ≈ 4.700 бита
```

**Пример 5:** Информация в растровом изображении

Чёрно-белое изображение 100×100 пикселей, каждый пиксель может быть чёрным или белым.

Количество пикселей: 100 × 100 = 10 000
Каждый пиксель несёт 1 бит информации (2 варианта)
Общее количество информации: 10 000 бит = 1 250 байт ≈ 1.22 КБ

Если изображение 256 градаций серого (8 бит на пиксель):
```
I_пиксель = log₂(256) = 8 бит
I_общая = 10 000 × 8 = 80 000 бит = 10 000 байт ≈ 9.77 КБ
```

### Примеры расчётов по формуле Шеннона

**Пример 6:** Неравновероятные исходы

Имеется источник, который выдаёт три символа: A, B, C с вероятностями:
- p(A) = 0.5
- p(B) = 0.25
- p(C) = 0.25

Энтропия:
```
H = -(0.5 × log₂(0.5) + 0.25 × log₂(0.25) + 0.25 × log₂(0.25))
H = -(0.5 × (-1) + 0.25 × (-2) + 0.25 × (-2))
H = -(-0.5 - 0.5 - 0.5) = 1.5 бита
```

Средняя информация на символ — 1.5 бита. Это меньше, чем для трёх равновероятных символов (log₂(3) ≈ 1.585 бита), так как символ A более предсказуем.

**Пример 7:** Энтропия русского текста

Исследования показывают, что в русском языке буквы встречаются с разной частотой:
- Буква "О" — около 10.97%
- Буква "Е" — около 8.45%
- Буква "А" — около 8.01%
- ...
- Буква "Ф" — около 0.26%
- Буква "Щ" — около 0.06%

Если бы все 33 буквы были равновероятны, энтропия была бы:
```
H_макс = log₂(33) ≈ 5.044 бита
```

Но с учётом реальных частот, энтропия русского текста составляет примерно:
```
H_реальная ≈ 4.35 бита на символ
```

Это означает, что русский текст более предсказуем, чем случайная последовательность букв, что используется алгоритмами сжатия (глава 1.12).

**Пример 8:** Информация в сообщении о выигрыше

Вы участвуете в лотерее, где вероятность выигрыша 1%, а проигрыша 99%.

Если вам сообщили, что вы выиграли:
```
I_выигрыш = -log₂(0.01) = log₂(100) ≈ 6.644 бита
```

Если сообщили, что проиграли:
```
I_проигрыш = -log₂(0.99) ≈ 0.0145 бита
```

Сообщение о редком событии (выигрыше) несёт гораздо больше информации, чем сообщение о ожидаемом событии (проигрыше).

## Семантическая мера информации

### Определение и сущность

**Семантическая мера информации** — это подход к измерению информации, при котором учитывается **смысловое содержание** сообщения, его **содержательность** и **новизна** для получателя.

С семантической точки зрения одно и то же сообщение может содержать разное количество информации для разных получателей в зависимости от их предварительных знаний.

**Ключевые аспекты семантической меры:**

1. **Новизна** — сообщение содержит информацию только если оно сообщает нечто новое
2. **Понятность** — получатель должен понимать содержание сообщения
3. **Контекст** — смысл зависит от контекста и знаний получателя
4. **Достоверность** — ложная информация снижает семантическую ценность

### Принцип семантической меры

Семантическая мера может быть представлена как отношение:

```
Ic = Iтезаурус / Iсообщение
```

где:
- **Ic** — семантическая мера информации (содержательность)
- **Iтезаурус** — информация, соответствующая знаниям получателя (тезаурус)
- **Iсообщение** — информация в сообщении

**Тезаурус** — это совокупность знаний, которыми обладает получатель информации в данной предметной области.

### Зависимость от тезауруса получателя

Семантическая ценность информации зависит от соотношения тезауруса получателя и сложности сообщения:

1. **Тезаурус слишком мал** (получатель не понимает терминологию):
   - Сообщение непонятно
   - Семантическая ценность близка к нулю
   - Пример: научная статья по квантовой физике для школьника

2. **Тезаурус оптимален** (соответствует уровню сообщения):
   - Сообщение понятно и содержит новые знания
   - Максимальная семантическая ценность
   - Пример: учебник для студента соответствующего курса

3. **Тезаурус слишком велик** (получатель уже всё знает):
   - Сообщение не содержит новой информации
   - Семантическая ценность близка к нулю
   - Пример: учебник для начальных классов для профессора

### Примеры семантической меры

**Пример 9:** Прогноз погоды

Синтаксически: сообщение "Завтра будет дождь" содержит около 150 бит (примерно 19 символов × 8 бит).

Семантически:
- Для человека, планирующего пикник — **высокая ценность** (влияет на планы)
- Для человека, работающего в офисе — **средняя ценность**
- Для человека, уже знающего прогноз — **нулевая ценность** (нет новизны)

**Пример 10:** Учебная информация

Фраза "Квадрат гипотенузы равен сумме квадратов катетов":

Для ученика 5 класса:
- Непонятна (недостаточный тезаурус)
- Семантическая ценность ≈ 0

Для ученика 8 класса, изучающего теорему Пифагора:
- Новая и понятная информация
- Максимальная семантическая ценность

Для студента математического факультета:
- Давно известная информация
- Семантическая ценность ≈ 0

**Пример 11:** Новостное сообщение

Новость "Открыт новый элемент с атомным номером 119":

Для учёного-химика:
- Революционная новость
- Очень высокая семантическая ценность

Для обычного человека:
- Умеренная ценность (интересно, но не применимо)

Для человека, не интересующегося наукой:
- Низкая семантическая ценность

**Пример 12:** Дублирование информации

Первое упоминание: "Столица Франции — Париж"
- Для не знающего — высокая семантическая ценность

Второе упоминание той же информации:
- Семантическая ценность = 0 (нет новизны)

Хотя синтаксически оба сообщения одинаковы, семантически второе не несёт информации.

## Прагматическая мера информации

### Определение и сущность

**Прагматическая мера информации** — это подход к измерению информации с точки зрения её **полезности**, **ценности** и **влияния на достижение цели** получателя.

Прагматическая мера оценивает не просто смысл информации, а её **практическую значимость** для конкретного получателя в конкретной ситуации.

**Ключевые аспекты прагматической меры:**

1. **Целесообразность** — насколько информация помогает достичь цели
2. **Своевременность** — информация ценна в нужный момент времени
3. **Полнота** — достаточность информации для принятия решения
4. **Достоверность** — надёжность информации
5. **Актуальность** — соответствие текущей ситуации

### Формализация прагматической меры

Прагматическую меру можно выразить через изменение вероятности достижения цели:

```
Ip = P(после) - P(до)
```

где:
- **Ip** — прагматическая мера информации
- **P(после)** — вероятность достижения цели после получения информации
- **P(до)** — вероятность достижения цели до получения информации

Чем больше информация увеличивает вероятность достижения цели, тем она ценнее с прагматической точки зрения.

### Факторы прагматической ценности

**Факторы, увеличивающие прагматическую ценность:**
- Актуальность для текущих задач
- Возможность практического применения
- Влияние на принятие важных решений
- Своевременность получения
- Достоверность источника

**Факторы, снижающие прагматическую ценность:**
- Устаревшая информация
- Нерелевантная для целей получателя
- Недостоверная или неполная информация
- Избыточная информация (информационная перегрузка)

### Примеры прагматической меры

**Пример 13:** Информация о ДТП на дороге

Сообщение: "На шоссе М1 произошло ДТП, образовалась пробка"

Синтаксически: около 400 бит

Семантически: понятно всем водителям

Прагматически:
- **Для водителя, едущего по М1** — очень высокая ценность (позволит выбрать объездной путь, сэкономит часы времени)
- **Для водителя в другом городе** — нулевая ценность
- **Для пешехода** — нулевая ценность

**Пример 14:** Биржевая информация

Информация: "Акции компании X выросли на 15%"

Для инвестора, владеющего акциями компании X:
- **Очень высокая прагматическая ценность** (решение о продаже, прибыль)

Для инвестора с другим портфелем:
- **Низкая прагматическая ценность**

Для человека, не занимающегося инвестициями:
- **Нулевая прагматическая ценность**

**Пример 15:** Медицинская информация

Информация: "Препарат А эффективен против заболевания Б"

Для больного с заболеванием Б:
- **Критически высокая прагматическая ценность** (может спасти жизнь)

Для врача, лечащего это заболевание:
- **Высокая прагматическая ценность** (улучшит лечение пациентов)

Для здорового человека:
- **Низкая прагматическая ценность** (может пригодиться в будущем)

**Пример 16:** Срочность информации

Информация: "Завтра экзамен перенесён на следующую неделю"

Получена за день до экзамена:
- **Очень высокая прагматическая ценность** (можно лучше подготовиться)

Получена через неделю после экзамена:
- **Нулевая прагматическая ценность** (устарела)

**Пример 17:** Информация для принятия решений

Предприниматель выбирает между двумя проектами A и B.

Информация: "Рынок для проекта A сокращается на 20% ежегодно"

Прагматическая ценность:
- Очень высокая: влияет на выбор проекта, может предотвратить убытки
- Позволяет избежать неверного решения

Без этой информации вероятность успеха: 50% (случайный выбор)
С этой информацией вероятность успеха: 80% (осознанный выбор проекта B)

Прагматическая мера: Ip = 0.8 - 0.5 = 0.3 (или 30%)

## Сравнение трёх мер информации

### Общая таблица сравнения

| Аспект               | Синтаксическая мера      | Семантическая мера       | Прагматическая мера      |
|----------------------|--------------------------|--------------------------|--------------------------|
| **Что измеряет**     | Количество символов/битов | Смысл, новизна           | Полезность, ценность     |
| **Зависит от**       | Объём данных, кодировка   | Знания получателя        | Цели получателя          |
| **Одинакова для всех**| Да                       | Нет                      | Нет                      |
| **Применение**       | Хранение, передача        | Обучение, коммуникация   | Принятие решений         |
| **Измеримость**      | Легко (биты, байты)       | Сложно (субъективно)     | Очень сложно             |
| **Пример единиц**    | Биты, байты, КБ, МБ       | Относительная шкала      | Относительная шкала      |

### Пример сравнения на одном сообщении

**Сообщение:** "Температура процессора 95°C" (200 бит)

**Синтаксическая мера:**
- 25 символов × 8 бит = 200 бит = 25 байт
- Одинакова для всех получателей

**Семантическая мера:**
- Для программиста: высокая (понимает значение и последствия)
- Для ребёнка: низкая (не понимает контекста)
- Для инженера, уже знающего температуру: нулевая (нет новизны)

**Прагматическая мера:**
- Для владельца компьютера: очень высокая (перегрев, нужно действовать срочно!)
- Для человека без компьютера: нулевая
- Для инженера другого компьютера: нулевая

### Взаимосвязь трёх мер

Три меры информации не противоречат, а дополняют друг друга:

```
Синтаксическая → Семантическая → Прагматическая
   (основа)         (понимание)       (применение)
```

1. **Синтаксическая мера** — необходимая база: без физического носителя информации нет ни смысла, ни пользы
2. **Семантическая мера** — добавляет понимание: бессмысленные данные не могут быть полезны
3. **Прагматическая мера** — венчает пирамиду: даже понятная информация бесполезна, если не применима к целям

## Практическая значимость и применение

### Применение синтаксической меры

**В технических системах:**
- Расчёт ёмкости носителей (жёсткие диски, SSD, оперативная память)
- Оценка скорости передачи данных (Мбит/с)
- Расчёт пропускной способности каналов связи
- Оптимизация алгоритмов сжатия (глава 1.12)

**Формулы для расчёта:**
```
Время передачи = Размер данных / Скорость канала
Объём хранилища = Количество файлов × Средний размер файла
```

### Применение семантической меры

**В системах обработки информации:**
- Поисковые системы (релевантность документов)
- Системы рекомендаций (персонализация контента)
- Образовательные системы (адаптация материала под уровень ученика)
- Фильтрация спама (отделение полезных сообщений от мусора)

**Методы оценки:**
- Анализ тезауруса пользователя
- Учёт контекста и истории взаимодействий
- Машинное обучение для оценки релевантности

### Применение прагматической меры

**В системах поддержки принятия решений:**
- Бизнес-аналитика (BI-системы)
- Медицинские диагностические системы
- Финансовые аналитические системы
- Системы управления производством

**Критерии оценки:**
- Влияние на ключевые показатели (KPI)
- ROI (возврат инвестиций) от использования информации
- Своевременность предоставления информации
- Точность и достоверность данных

### Практический пример: организация информации на сайте

**Синтаксический уровень:**
- Оптимизация размера веб-страниц для быстрой загрузки
- Сжатие изображений и скриптов
- Использование эффективных кодировок (UTF-8)

**Семантический уровень:**
- Структурирование контента для понятности
- Использование понятной терминологии
- Адаптация контента под аудиторию
- SEO-оптимизация (поисковые системы понимают содержание)

**Прагматический уровень:**
- Размещение важной информации на видных местах
- Персонализация контента под нужды пользователя
- Рекомендации релевантных товаров/статей
- Call-to-action кнопки в нужных местах

## Ключевые термины

**Бит** — минимальная единица измерения информации, соответствующая выбору из двух равновероятных вариантов

**Байт** — единица информации, равная 8 битам

**Формула Хартли** — формула для расчёта количества информации при равновероятных событиях: I = log₂(N)

**Формула Шеннона** — формула для расчёта энтропии (среднего количества информации) при неравновероятных событиях: H = -∑(pᵢ × log₂(pᵢ))

**Энтропия** — мера неопределённости источника информации, среднее количество информации на символ

**Синтаксическая мера информации** — количественная мера, учитывающая только объём данных в битах/байтах, независимо от смысла

**Семантическая мера информации** — мера, учитывающая смысловое содержание, новизну и понятность информации для получателя

**Прагматическая мера информации** — мера, учитывающая полезность и ценность информации для достижения целей получателя

**Тезаурус** — совокупность знаний получателя в предметной области, влияющая на семантическую ценность информации

**Информационная ценность** — степень полезности информации для достижения целей и принятия решений

## Контрольные вопросы

1. **Теоретический вопрос:** Объясните разницу между тремя мерами информации: синтаксической, семантической и прагматической. Приведите пример одного и того же сообщения, которое имеет разную ценность с точки зрения каждой из этих мер.

2. **Практическая задача (формула Хартли):** В базе данных хранятся записи о студентах. Каждая запись содержит: номер группы (32 варианта), фамилию (выбор из справочника 1024 фамилий), оценку (5 вариантов). Рассчитайте количество информации в каждом поле и общее количество информации в записи о студенте.

3. **Практическая задача (формула Шеннона):** Источник генерирует четыре символа с вероятностями: A (0.4), B (0.3), C (0.2), D (0.1). Рассчитайте энтропию источника. Сравните полученное значение с энтропией для четырёх равновероятных символов. Объясните разницу.

4. **Анализ ситуации:** Вы получили электронное письмо с информацией о предстоящей конференции по информационным технологиям. Проанализируйте прагматическую ценность этого письма для: а) студента-программиста, б) преподавателя информатики, в) пенсионера, не работающего в IT-сфере. Обоснуйте различия в прагматической ценности.

5. **Практическое применение:** Объясните, почему знание о разных мерах информации важно при разработке: а) системы резервного копирования данных, б) образовательной онлайн-платформы, в) системы бизнес-аналитики. Какая мера наиболее важна в каждом случае и почему?

---

**Данная глава раскрыла фундаментальные подходы к измерению информации.** Понимание синтаксической, семантической и прагматической мер критически важно для эффективной работы с информацией в любой области деятельности. В следующих главах мы продолжим изучение свойств информации и способов её обработки, опираясь на полученные знания о том, как можно количественно и качественно оценивать информацию.
